<!DOCTYPE html>
<html lang="en">

<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-RB92YJ3CLH"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-RB92YJ3CLH');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Free online transcription tool with real-time speech recognition. Convert speech to text instantly in your browser. No downloads or uploads required." />
    <meta name="keywords"
        content="speech to text, transcription tool, voice to text, online transcription, speech recognition, audio transcription, free transcription" />
    <meta name="author" content="Small Web Tools" />
    <meta name="robots" content="index, follow" />
    <link rel="canonical" href="https://imxj.github.io/apps/easy-transcript/" />

    <!-- Open Graph meta tags -->
    <meta property="og:title" content="Easy Transcript - Free Online Speech to Text Tool" />
    <meta property="og:description"
        content="Convert speech to text instantly with real-time transcription. Free online tool using advanced speech recognition." />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://imxj.github.io/apps/easy-transcript/" />
    <meta property="og:site_name" content="Small Web Tools" />

    <!-- Twitter Card meta tags -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Easy Transcript - Speech to Text Tool" />
    <meta name="twitter:description"
        content="Free online transcription with real-time speech recognition. Convert voice to text instantly." />

    <link rel="icon" href="../favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon">
    <title>Easy Transcript - Free Online Speech to Text Transcription | Small Web Tools</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }

        #transcript-container {
            position: relative;
            margin-top: 20px;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            max-height: 300px;
            /* Set a max height to allow scrolling */
            overflow-y: auto;
            /* Add vertical scroll if the content overflows */
            border: 1px solid #ccc;
            /* Add border for better visibility */
        }

        #transcript {
            padding: 10px;
            font-size: 1.2em;
            overflow-wrap: break-word;
            word-wrap: break-word;
            white-space: pre-wrap;
            /* Maintain line breaks */
            text-align: left;
            /* Align text to the left */
        }

        .button-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 10px;
            margin-bottom: 20px;
        }

        button {
            padding: 15px 20px;
            font-size: 1.2em;
            border: none;
            border-radius: 5px;
            background-color: #007bff;
            color: white;
            cursor: pointer;
            display: inline-block;
        }

        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }

        /* Footnote styles */
        .footnote {
            margin-top: 20px;
            font-size: 0.6em;
            color: #555;
        }

        /* Media query for smaller screens (mobile) */
        @media (max-width: 768px) {
            button {
                padding: 10px 15px;
                font-size: 1em;
                flex: 1;
                /* Allows buttons to resize and fit in a row */
                min-width: 90px;
                /* Minimum width to keep the button legible */
            }
        }

        /* Audio player */
        #audio-player {
            margin-top: 20px;
            width: 100%;
            max-width: 600px;
        }
    </style>
</head>

<body>
    <h1>Easy Transcript</h1>
    <button id="start-btn">Start</button>
    <button id="stop-btn" disabled>Stop</button>
    <button id="email-btn" disabled>Email</button>
    <button id="play-audio-btn" disabled>Play Audio</button>
    <button id="download-audio-btn" disabled>Download Audio</button>


    <div id="transcript-container">
        <div id="transcript">Transcript will appear here...</div>
    </div>
    <!-- Audio player -->
    <audio id="audio-player" controls></audio>
    <!-- Footnote -->
    <div class="footnote">
        Best performance on Google Chrome browser.
    </div>
    <script src="https://cdn.rawgit.com/mattdiamond/Recorderjs/08e7abd9/dist/recorder.js"></script>

    <script>
        // Make sure the script runs after the DOM has fully loaded
        document.addEventListener('DOMContentLoaded', () => {
            // Check if the browser supports the necessary APIs
            if (!('webkitSpeechRecognition' in window) || !('MediaRecorder' in window)) {
                alert('Sorry, your browser does not support the necessary features. Please use Google Chrome.');
                return;
            }

            // Initialize the Chrome-specific webkitSpeechRecognition object
            const recognition = new webkitSpeechRecognition();

            // Set recognition parameters
            recognition.continuous = true; // Set to true for continuous recognition
            recognition.interimResults = true; // Show interim results for real-time feedback
            recognition.lang = 'en-US'; // Set the language

            // Get the elements
            const startBtn = document.getElementById('start-btn');
            const stopBtn = document.getElementById('stop-btn');
            const emailBtn = document.getElementById('email-btn');
            const downloadAudioBtn = document.getElementById('download-audio-btn');
            const playAudioBtn = document.getElementById('play-audio-btn');

            const transcriptDiv = document.getElementById('transcript');
            const transcriptContainer = document.getElementById('transcript-container');
            const audioPlayer = document.getElementById('audio-player');


            // Flags to manage recognition state and timestamps
            let isRecognizing = false;
            let finalTranscript = '';
            let startTimestamp = ''; // Store the start timestamp
            let endTimestamp = ''; // Store the end timestamp

            // Audio recording variables
            let audioContext;
            let recorder;
            let accumulatedBlobs = []; // Array to store all audio blobs

            // Start recognition and recording
            startBtn.addEventListener('click', async () => {
                if (!isRecognizing) {
                    recognition.start();
                    isRecognizing = true;
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    emailBtn.disabled = true; // Disable the email button while listening
                    downloadAudioBtn.disabled = true; // Disable the download button while recording
                    playAudioBtn.disabled = true; // Disable the play audio button while recording
                    transcriptDiv.textContent = 'Listening...';

                    // Start audio recording
                    try {
                        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        const input = audioContext.createMediaStreamSource(stream);
                        recorder = new Recorder(input, { numChannels: 1 });
                        recorder.record();

                        // Capture the start timestamp
                        const now = new Date();
                        startTimestamp = now.toLocaleDateString() + ', ' + now.toLocaleTimeString();
                    } catch (error) {
                        console.error('Error accessing microphone:', error);
                        alert('Unable to access the microphone.');
                    }
                }
            });

            // Stop recognition
            stopBtn.addEventListener('click', () => {
                if (isRecognizing) {
                    recognition.stop();
                    isRecognizing = false;
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                    emailBtn.disabled = false; // Enable the email button
                    playAudioBtn.disabled = false; // Enable the play audio button
                    downloadAudioBtn.disabled = false;
                    transcriptDiv.textContent += ' (Stopped Listening)';
                    // Export audio using Recorder.js
                    recorder.stop();
                    recorder.exportWAV(blob => {
                        accumulatedBlobs.push(blob); // Store the blob in the accumulatedBlobs array
                        recorder.clear();
                    });
                    // Capture the end timestamp
                    const now = new Date();
                    endTimestamp = now.toLocaleDateString() + ', ' + now.toLocaleTimeString();
                }
            });

            // Download the recorded audio
            downloadAudioBtn.addEventListener('click', () => {
                concatenateWavBlobs(accumulatedBlobs).then(concatenatedBlob => {
                    const audioUrl = URL.createObjectURL(concatenatedBlob);
                    const a = document.createElement('a');
                    a.href = audioUrl;
                    a.download = 'recording.wav';
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                });
            });

            // Play the recorded audio
            playAudioBtn.addEventListener('click', () => {
                // Combine all blobs into one
                concatenateWavBlobs(accumulatedBlobs).then(concatenatedBlob => {
                    const audioUrl = URL.createObjectURL(concatenatedBlob);
                    audioPlayer.src = audioUrl;
                    audioPlayer.play();
                });
            });

            // Concatenate multiple WAV blobs into a single WAV Blob
            function concatenateWavBlobs(blobs) {
                return new Promise((resolve, reject) => {
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const totalBuffers = [];

                    // Decode all blobs to AudioBuffers
                    const decodePromises = blobs.map(blob => {
                        return new Promise((resolve, reject) => {
                            const reader = new FileReader();
                            reader.onload = () => {
                                audioContext.decodeAudioData(reader.result, resolve, reject);
                            };
                            reader.onerror = reject;
                            reader.readAsArrayBuffer(blob);
                        });
                    });

                    // When all blobs are decoded, concatenate them
                    Promise.all(decodePromises).then(buffers => {
                        const totalLength = buffers.reduce((sum, buffer) => sum + buffer.length, 0);
                        const outputBuffer = audioContext.createBuffer(1, totalLength, audioContext.sampleRate);
                        let offset = 0;

                        buffers.forEach(buffer => {
                            outputBuffer.getChannelData(0).set(buffer.getChannelData(0), offset);
                            offset += buffer.length;
                        });

                        // Convert the concatenated buffer to a WAV Blob
                        const wavBlob = audioBufferToWavBlob(outputBuffer);
                        resolve(wavBlob);
                    }).catch(reject);
                });
            }

            // Convert AudioBuffer to WAV Blob
            function audioBufferToWavBlob(buffer) {
                const numberOfChannels = buffer.numberOfChannels;
                const length = buffer.length * numberOfChannels * 2 + 44;
                const result = new DataView(new ArrayBuffer(length));
                const channels = [];
                let offset = 0;
                let pos = 0;

                // Write WAV header
                writeString(result, pos, 'RIFF'); pos += 4;
                result.setUint32(pos, length - 8, true); pos += 4;
                writeString(result, pos, 'WAVE'); pos += 4;
                writeString(result, pos, 'fmt '); pos += 4;
                result.setUint32(pos, 16, true); pos += 4;
                result.setUint16(pos, 1, true); pos += 2;
                result.setUint16(pos, numberOfChannels, true); pos += 2;
                result.setUint32(pos, buffer.sampleRate, true); pos += 4;
                result.setUint32(pos, buffer.sampleRate * 4, true); pos += 4;
                result.setUint16(pos, numberOfChannels * 2, true); pos += 2;
                result.setUint16(pos, 16, true); pos += 2;
                writeString(result, pos, 'data'); pos += 4;
                result.setUint32(pos, length - pos - 4, true); pos += 4;

                // Write interleaved data
                for (let i = 0; i < buffer.numberOfChannels; i++) {
                    channels.push(buffer.getChannelData(i));
                }
                while (pos < length) {
                    for (let i = 0; i < numberOfChannels; i++) {
                        const sample = Math.max(-1, Math.min(1, channels[i][offset])); // Clamp
                        result.setInt16(pos, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                        pos += 2;
                    }
                    offset++;
                }

                // Create a Blob for the WAV file
                return new Blob([result], { type: 'audio/wav' });
            }

            // Utility function to write strings to DataView
            function writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            // Process the results
            recognition.onresult = (event) => {
                let interimTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const result = event.results[i];
                    if (result.isFinal) {
                        const timestamp = new Date().toLocaleTimeString();
                        const sentenceWithTimestamp = `[${timestamp}] ${result[0].transcript}\n`;
                        finalTranscript += sentenceWithTimestamp;
                    } else {
                        interimTranscript += result[0].transcript;
                    }
                }
                transcriptDiv.textContent = finalTranscript + interimTranscript;

                // Auto-scroll to the bottom of the transcript container
                transcriptContainer.scrollTop = transcriptContainer.scrollHeight;
            };

            // Handle errors
            recognition.onerror = (event) => {
                transcriptDiv.textContent = 'Error occurred in recognition: ' + event.error;
            };

            // Restart recognition when it ends to keep it continuous
            recognition.onend = () => {
                if (isRecognizing) {
                    recognition.start(); // Restart recognition
                }
            };

            // Email the transcript
            emailBtn.addEventListener('click', () => {
                const subject = encodeURIComponent('Transcript from ' + startTimestamp + ' to ' + endTimestamp);
                const body = encodeURIComponent(finalTranscript);
                const mailtoLink = `mailto:?subject=${subject}&body=${body}`;
                window.open(mailtoLink, '_blank'); // Open email client in a new window/tab
            });
        });
    </script>
</body>

</html>